{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaOIA_reconnaisance_extraction_entites.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTXni_WXMpqY"
      },
      "source": [
        "# **Reconnaissance des Entités nommées (REN)**:\n",
        "Script de reconnaissance et extraction et entités nommées de textes. \n",
        "\n",
        "Bibliothèque python utilisée: SpaCy.\n",
        "\n",
        "Documents d'entrée: fichiers .txt contenant les textes sur lesquels effectuer la reconnaissane des entitiés nommées.\n",
        "\n",
        "Fichiers de sortie : 1 fichier .txt contenant une liste des entités nommées :\n",
        "- personnes\n",
        "- lieux\n",
        "- organisations\n",
        "- divers (évènements, oeuvres d'art)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMpdWhDUH2Me",
        "cellView": "form"
      },
      "source": [
        "#@markdown # Connexion à son compte Google Drive et choix de la langue\n",
        "\n",
        "#@markdown Lancer la cellule, cliquer sur le lien généré en dessous qui ouvrira un nouvel onglet du navigateur. \n",
        "\n",
        "#@markdown Cliquer sur son compte google, accepter les autorisations, copier le lien qui s'afficher et le coller dans la case prévu à cet effet en dessous de cette cellule.\n",
        "\n",
        "#@markdown Choisir la langue des textes du corpus pour la reconnaissance:\n",
        "\n",
        "Langue_de_reconnaissance = \"Francais\" #@param [\"Anglais\", \"Italien\", \"Francais\", \"Allemand\", \"Espagnol\"]\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from google.colab import drive\n",
        "!pip install spacy==3.2\n",
        "\n",
        "if Langue_de_reconnaissance == 'Anglais':\n",
        "  !python -m spacy download en_core_web_lg\n",
        "  a_importer = 'en_core_web_lg'\n",
        "if Langue_de_reconnaissance == 'Allemand':\n",
        "  !python -m spacy download de_core_news_lg\n",
        "  a_importer = 'de_core_news_lg'\n",
        "if Langue_de_reconnaissance == \"Francais\":\n",
        "  !python -m spacy download fr_core_news_lg\n",
        "  a_importer = 'fr_core_news_lg'\n",
        "if Langue_de_reconnaissance == \"Espagnol\":\n",
        "  !python -m spacy download es_core_news_lg\n",
        "  a_importer = 'es_core_news_lg'\n",
        "if Langue_de_reconnaissance == \"Italien\":\n",
        "  !python -m spacy download it_core_news_lg\n",
        "  a_importer = 'it_core_news_lg'\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(a_importer)\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/tutoriel_extraction_cartographie-main/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32HK7-OWe594",
        "cellView": "form"
      },
      "source": [
        "#@markdown # Reconnaissance et téléchargement des entités nommées\n",
        "chemin_vers_le_dossier_de_travail = '/content/drive/My Drive/reconnaissance entites'#@param {type:\"string\"}\n",
        "os.chdir(chemin_vers_le_dossier_de_travail)\n",
        "\n",
        "chemin_vers_le_dossier_de_fichiers_txt = \"/content/drive/My Drive/reconnaissance entites/dossier de fichiers textes\"#@param {type:\"string\"}\n",
        "nlp.max_length = 150000000\n",
        "nom_du_dossier_des_entites = \"entites corpus\" #@param {type:\"string\"}\n",
        "if not os.path.exists(nom_du_dossier_des_entites):\n",
        "  os.mkdir(nom_du_dossier_des_entites)\n",
        "os.chdir(nom_du_dossier_des_entites)\n",
        "\n",
        "#@markdown Télécharger : \n",
        "entites_lieux = True #@param {type:\"boolean\"}\n",
        "entites_personnes = True #@param {type:\"boolean\"}\n",
        "entites_organisations = True #@param {type:\"boolean\"}\n",
        "entites_divers = True #@param {type:\"boolean\"}\n",
        "\n",
        "nom_glob = ''.join(chemin_vers_le_dossier_de_fichiers_txt+\"*.txt\")\n",
        "for element in glob.glob(nom_glob):\n",
        "  with open (element, \"r\") as myfile:\n",
        "    data=myfile.read()\n",
        "    doc = nlp(data)\n",
        "    nom_fichier = os.path.basename(element)\n",
        "\n",
        "    if entites_lieux == True:\n",
        "      nouveau_nom_lieux = ''.join(\"Lieux_\" + nom_fichier)\n",
        "      with open(nouveau_nom_lieux, 'w') as my_locs:\n",
        "        for ent in doc.ents:\n",
        "          if ent.label_ == 'LOC':\n",
        "            entites_loc = \"\".join([str(ent.text),\"\\n\"])\n",
        "            my_locs.write(entites_loc)\n",
        "\n",
        "    if entites_organisations == True:\n",
        "      nouveau_nom_org = ''.join(\"Org_\" + nom_fichier)\n",
        "      with open(nouveau_nom_org, 'w') as my_orgs:\n",
        "        for ent in doc.ents:\n",
        "          if ent.label_ == 'ORG':\n",
        "            entites_org = \"\".join([str(ent.text),\"\\n\"])\n",
        "            my_orgs.write(entites_org)\n",
        "\n",
        "    if entites_divers == True:\n",
        "      nouveau_nom_nat = ''.join(\"Div_\" + nom_fichier)\n",
        "      with open(nouveau_nom_nat, 'w') as my_nats:\n",
        "        for ent in doc.ents:\n",
        "          if ent.label_ == 'MISC':\n",
        "            entites_nat = \"\".join([str(ent.text),\"\\n\"])\n",
        "            my_nats.write(entites_nat)\n",
        "\n",
        "    if entites_personnes == True:\n",
        "      nouveau_nom_pers = ''.join(\"Pers_\" + nom_fichier)\n",
        "      with open(nouveau_nom_pers, 'w') as my_pers:\n",
        "        for ent in doc.ents:\n",
        "          if ent.label_ == 'PER':\n",
        "            entites_per = \"\".join([str(ent.text),\"\\n\"])\n",
        "            my_pers.write(entites_per)\n"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}