{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaOIA_reconnaisance_extraction_entites (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTXni_WXMpqY"
      },
      "source": [
"# **Reconnaissance des Entités nommées (REN)**\n",
        "Ce script permet la reconnaissance et l'extraction des entités nommées de documents. Il utilise la bibliothèque python SpaCy.\n",
        "\n",
        "*Documents d'entrée* : fichiers .txt contenant les textes sur lesquels effectuer la reconnaissane des entités nommées.\n",
        "\n",
        "*Documents de sortie* : pour chaque document, un fichier .txt par type d'entités (contenant la liste des entités nommées) :\n",
        "- personnes\n",
        "- lieux\n",
        "- organisations\n",
        "- divers (évènements, oeuvres d'art)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMpdWhDUH2Me",
        "cellView": "form"
      },
      "source": [
        "#@markdown # Connecter le notebook à son compte Google Drive et choix de la langue des documents\n",
        "\n",
        "#@markdown - Lancer la cellule\n",
        "#@markdown - Cliquer sur « Exécuter malgré tout » lors de l’apparition du message d’avertissement indiquant que le notebook n’a pas été créé par Google\n",
        "#@markdown - Cliquer sur « Se connecter à Google Drive » lors de l’apparition du second message d’avertissement pour donner l’autorisation au notebook d’accéder à vos fichiers Google Drive\n",
        "#@markdown - Choisir son compte Gmail puis cliquer sur « Autoriser »\n",
        "\n",
        "#@markdown Choisir la langue des textes du corpus pour la reconnaissance des entités nommées :\n",
        "\n",
        "Langue_de_reconnaissance = \"Francais\" #@param [\"Anglais\", \"Italien\", \"Francais\", \"Allemand\", \"Espagnol\"]\n",
        "\n",
        "import glob\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/tutoriel_extraction_cartographie-main/\n",
        "!pip install spacy==3.2\n",
        "\n",
        "if Langue_de_reconnaissance == 'Anglais':\n",
        "  !python -m spacy download en_core_web_lg\n",
        "  a_importer = 'en_core_web_lg'\n",
        "if Langue_de_reconnaissance == 'Allemand':\n",
        "  !python -m spacy download de_core_news_lg\n",
        "  a_importer = 'de_core_news_lg'\n",
        "if Langue_de_reconnaissance == \"Francais\":\n",
        "  !python -m spacy download fr_core_news_lg\n",
        "  a_importer = 'fr_core_news_lg'\n",
        "if Langue_de_reconnaissance == \"Espagnol\":\n",
        "  !python -m spacy download es_core_news_lg\n",
        "  a_importer = 'es_core_news_lg'\n",
        "if Langue_de_reconnaissance == \"Italien\":\n",
        "  !python -m spacy download it_core_news_lg\n",
        "  a_importer = 'it_core_news_lg'\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(a_importer)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32HK7-OWe594",
        "cellView": "form"
      },
      "source": [
        "#@markdown # Reconnaissance et extraction des entités nommées\n",
        "\n",
        "#@markdown ####Indiquer le chemin absolu vers le dossier de travail sur le Google Drive :\n",
        "chemin_vers_le_dossier_de_travail = '/content/drive/My Drive/scripts-main/guides_de_voyage/'#@param {type:\"string\"}\n",
        "os.chdir(chemin_vers_le_dossier_de_travail)\n",
        "\n",
        "#@markdown ####Indiquer le chemin absolu vers le dossier où sont stockés les fichiers textes :\n",
        "chemin_vers_le_dossier_de_fichiers_txt = '/content/drive/My Drive/scripts-main/guides_de_voyage/dossier de fichiers textes/'#@param {type:\"string\"}\n",
        "nlp.max_length = 150000000\n",
        "\n",
        "#@markdown ####Indiquer le nom du dossier qui sera créé et dans lequel les listes d'entités vont être téléchargées :\n",
        "nom_du_dossier_des_entites = \"entites corpus\" #@param {type:\"string\"}\n",
        "if not os.path.exists(nom_du_dossier_des_entites):\n",
        "  os.mkdir(nom_du_dossier_des_entites)\n",
        "os.chdir(nom_du_dossier_des_entites)\n",
        "\n",
        "#@markdown Télécharger : \n",
        "entites_lieux = True #@param {type:\"boolean\"}\n",
        "entites_personnes = True #@param {type:\"boolean\"}\n",
        "entites_organisations = True #@param {type:\"boolean\"}\n",
        "entites_divers = True #@param {type:\"boolean\"}\n",
        "\n",
        "nom_glob = ''.join(chemin_vers_le_dossier_de_fichiers_txt+\"*.txt\")\n",
        "for element in glob.glob(nom_glob):\n",
        "  with open (element, \"r\") as myfile:\n",
        "    data=myfile.read()\n",
        "    doc = nlp(data)\n",
        "    nom_fichier = os.path.basename(element)\n",
        "\n",
        "    if entites_lieux == True:\n",
        "      nouveau_nom_lieux = ''.join(\"Lieux_\" + nom_fichier)\n",
        "      with open(nouveau_nom_lieux, 'w') as my_locs:\n",
        "        for ent in doc.ents:\n",
        "          if ent.label_ == 'LOC':\n",
        "            entites_loc = \"\".join([str(ent.text),\"\\n\"])\n",
        "            my_locs.write(entites_loc)\n",
        "\n",
        "    if entites_organisations == True:\n",
        "      nouveau_nom_org = ''.join(\"Org_\" + nom_fichier)\n",
        "      with open(nouveau_nom_org, 'w') as my_orgs:\n",
        "        for ent in doc.ents:\n",
        "          if ent.label_ == 'ORG':\n",
        "            entites_org = \"\".join([str(ent.text),\"\\n\"])\n",
        "            my_orgs.write(entites_org)\n",
        "\n",
        "    if entites_divers == True:\n",
        "      nouveau_nom_nat = ''.join(\"Div_\" + nom_fichier)\n",
        "      with open(nouveau_nom_nat, 'w') as my_nats:\n",
        "        for ent in doc.ents:\n",
        "          if ent.label_ == 'MISC':\n",
        "            entites_nat = \"\".join([str(ent.text),\"\\n\"])\n",
        "            my_nats.write(entites_nat)\n",
        "\n",
        "    if entites_personnes == True:\n",
        "      nouveau_nom_pers = ''.join(\"Pers_\" + nom_fichier)\n",
        "      with open(nouveau_nom_pers, 'w') as my_pers:\n",
        "        for ent in doc.ents:\n",
        "          if ent.label_ == 'PER':\n",
        "            entites_per = \"\".join([str(ent.text),\"\\n\"])\n",
        "            my_pers.write(entites_per)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
