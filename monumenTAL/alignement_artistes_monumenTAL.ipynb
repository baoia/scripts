{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alignement_artistes_monumenTAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPgY2q__eOx7"
      },
      "source": [
        "## Outil d'alignement des données : appliqué à des artistes sculpteurs\n",
        "\n",
        "Projet MonumenTAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qsN1sBMbs9t"
      },
      "source": [
        "#@title Installation des bibliothèques nécessaires et connexion à un compte Google Drive.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "''' \n",
        "Google Colab notebook.\n",
        "Python == 3.7.11\n",
        "\n",
        "BaOIA - La Contemporaine - Université de Nanterre\n",
        "'''\n",
        "\n",
        "\n",
        "## Installation des bibliothèques et connexion au compte Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "import re\n",
        "import glob\n",
        "import os\n",
        "import itertools\n",
        "import json\n",
        "import pandas as pd\n",
        "import urllib.parse, urllib.request, json\n",
        "import collections\n",
        "from collections import Counter\n",
        "!pip install wptools==0.4.17\n",
        "import wptools\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd /content/drive/My Drive/atelier_MonumenTAL/alignement/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2sqCIx5ttID"
      },
      "source": [
        "def CallWikifier(text, lang=\"fr\", threshold=1): \n",
        "\n",
        "  \"\"\" FROM: http://wikifier.org/info.html\n",
        "\n",
        "  Fonction qui associe chaque entitée nommée reconnue dans un texte à un identifiant\n",
        "  unique se rapportant à la base de donnée Wikidata. Cela permet d'identifier et de\n",
        "  désambiguiser les noms de personnages, de lieux, d'institutions. \n",
        "  \n",
        "  La fonction prend en entrée le texte (les noms, lieux etc.) ainsi que la langue\n",
        "  qu'il est possible de modifier ('en' pour anglais, 'fr' pour français) \n",
        "  \n",
        "  Il est possible de changer le seuil 'thresold' (entre 0.8 et 1.0): plus le taux est élevé,\n",
        "  plus de résultats seront repérés mais plus d'erreurs apparaissent. \"\"\"\n",
        "\n",
        "    data = urllib.parse.urlencode([\n",
        "        (\"text\", text), (\"lang\", lang),\n",
        "        (\"userKey\", \"nqvsutgqswvfmrcvyxjtopvpiukjtp\"),\n",
        "        (\"pageRankSqThreshold\", \"%g\" % threshold), (\"applyPageRankSqThreshold\", \"true\"),\n",
        "        (\"nTopDfValuesToIgnore\", \"200\"), (\"nWordsToIgnoreFromList\", \"200\"),\n",
        "        (\"wikiDataClasses\", \"true\"), (\"wikiDataClassIds\", \"false\"),\n",
        "        (\"support\", \"true\"), (\"ranges\", \"false\"), (\"minLinkFrequency\", \"4\"),\n",
        "        (\"includeCosines\", \"false\"), (\"maxMentionEntropy\", \"3\")\n",
        "        ])\n",
        "    url = \"http://www.wikifier.org/annotate-article\"\n",
        "    req = urllib.request.Request(url, data=data.encode(\"utf8\"), method=\"POST\")\n",
        "    with urllib.request.urlopen(req, timeout = 500) as f:\n",
        "        global response\n",
        "        response = f.read()\n",
        "        response = json.loads(response.decode(\"utf8\"))\n",
        "\n",
        "\n",
        "\n",
        "# Création des listes et dictionnaires qui vont contenir les informations \n",
        "# récupérées grâce à l'identifiant unique Wikidata.\n",
        "donnees_artistes_monumental = {}\n",
        "nom = []\n",
        "annee_naissance_search = []\n",
        "date_naissance_data = []\n",
        "date_deces_data = []\n",
        "lieu_naissance_data = []\n",
        "annee_deces_search = []\n",
        "lieu_deces_data = []\n",
        "lieu_naissance_net = []\n",
        "sexe=[]\n",
        "lieu_deces_net = []\n",
        "liste_donnees = []\n",
        "liste_perso_corpus = []\n",
        "itemid = []\n",
        "\n",
        "# Importation du fichier excel contenant la liste des artistes\n",
        "chemin_vers_le_fichier_excel = '/content/drive/My Drive/atelier_MonumenTAL/alignement/artistes_anglais.xlsx' #@param {type:\"string\"}\n",
        "export = pd.read_excel(chemin_vers_le_fichier_excel-\n",
        "liste_artistes = export.values.T[1].tolist()\n",
        "\n",
        "# Pour chaque artiste, appel de la fonction Callwikifier \n",
        "# Récupération des informations: date de naissance, date de décès,\n",
        "# lieu de naissance, lieu de décès, genre et enregistrement sous\n",
        "# forme de dictionnaire\n",
        "\n",
        "for artiste in liste_artistes:\n",
        "  CallWikifier(text=artiste, lang=\"en\")\n",
        "  try:\n",
        "    for annotation in response[\"annotations\"]: ## pour chaque réponse:\n",
        "      itemid = annotation[\"wikiDataItemId\"]\n",
        "      page = wptools.page(wikibase=itemid, lang=\"fr\")\n",
        "      page.get_wikidata()\n",
        "      page.get_parse()\n",
        "      infobox=page.data['infobox']\n",
        "      if infobox is not None:\n",
        "        nom = infobox.get(\"nom\")\n",
        "        tout=page.data['wikidata']\n",
        "        sexe=tout.get(\"sexe ou genre (P21)\")\n",
        "        date_naissance=infobox.get(\"date de naissance\")\n",
        "        annee_naissance_search = re.findall(r'\\b\\d{3,4}\\b', str(date_naissance)) ## Conserver uniquement les années\n",
        "        date_deces=infobox.get(\"date de décès\")\n",
        "        annee_deces_search = re.findall(r'\\b\\d{3,4}\\b', str(date_deces)) ### Conserver uniquement les années\n",
        "        lieu_naissance = infobox.get(\"lieu de naissance\") \n",
        "        lieu_naissance2 = re.sub(r'([()[\\]{}]|)', \"\",str(lieu_naissance))\n",
        "        lieu_naissance3 = re.sub(r'(<br>)(<br\\>)', \"\",str(lieu_naissance2))\n",
        "        lieu_naissance_net = re.sub(r'({{-}})', \"\",str(lieu_naissance3))\n",
        "        lieu_deces=infobox.get(\"lieu de décès\")\n",
        "        lieu_deces2 = re.sub(r'([()[\\]{}]|)', \"\",str(lieu_deces))\n",
        "        lieu_deces3 = re.sub(r'(<br>)(<br\\>)', \"\",str(lieu_deces2))\n",
        "        lieu_deces_net = re.sub(r'({{-}})', \"\",str(lieu_deces3))\n",
        "        donnees_artistes_monumental[nom] = {\"Date de naissance\" : annee_naissance_search, \"Date de deces\" : annee_deces_search, \n",
        "             \"Lieu de naissance\" : lieu_naissance_net, \"Lieu de deces\" : lieu_deces_net, \"Genre\": sexe}\n",
        "  except (TypeError, ValueError, LookupError) as tpe:\n",
        "    pass \n",
        "\n",
        "\n",
        "\n",
        "#@markdown Noms des fichiers de sortie:\n",
        "\n",
        "\n",
        "nom_fichier_liste_des_identifiants_wikidata = 'liste_identifiants_artistes_anglais.txt' #@param {type:\"string\"}\n",
        "with open(nom_fichier_liste_des_identifiants_wikidata, \"w\") as koui:\n",
        "    koui.write(str(itemid))\n",
        "\n",
        "nom_fichier_donnees_artistes = 'donnees_artistes_anglais.json' #@param {type:\"string\"}\n",
        "with open(nom_fichier_donnees_artistes, \"w\") as gjoi:\n",
        "  json.dump(donnees_artistes_monumental, gjoi, indent=4, ensure_ascii=False)\n",
        "\n",
        "nom_fichier_excel_donnees_artistes = 'informations_personnages.xlsx' #@param {type:\"string\"}\n",
        "df = pd.DataFrame(donnees)\n",
        "df2 = df.transpose()\n",
        "df2.to_excel(nom_fichier_excel_donnees_artistes)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}